{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1610876130170",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(60000, 28, 28, 1)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "## reshaping format to (batch, height, width, channels). As all the images are in grayscale, the number of channels is 1\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "## Convert Datatype of pixels to float \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "## Divide each image by 255\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5, array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32))"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#converting output into a layer output\n",
    "number_of_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "y_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "60000/60000 [==============================] - 495s 8ms/step - loss: 0.1384 - accuracy: 0.9616\n10000/10000 [==============================] - 19s 2ms/step - loss: 0.0753 - accuracy: 0.9786\nLoss :  0.07530723512172699\nSuccess Accurcy :  0.978600025177002\n"
    }
   ],
   "source": [
    "# Architecture One\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))    #first layer\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "BatchNormalization(axis=-1)     #normalizes the matrix\n",
    "\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))     #to reduce overfitting\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "#model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=1, steps_per_epoch=60000)\n",
    "result = model.evaluate(X_test, Y_test, steps = 10000)\n",
    "print(\"Loss : \", result[0])\n",
    "print(\"Success Accurcy : \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "60000/60000 [==============================] - 1527s 25ms/step - loss: 0.1273 - accuracy: 0.9625\n10000/10000 [==============================] - 44s 4ms/step - loss: 0.0548 - accuracy: 0.9828\nLoss :  0.05484215170145035\nSuccess Accurcy :  0.9828000068664551\n"
    }
   ],
   "source": [
    "# Architecture Two \n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model2.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "# Fully connected layer\n",
    "BatchNormalization()\n",
    "model2.add(Dense(512))\n",
    "model2.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model2.add(Dropout(0.2))     #to reduce overfitting\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model2.fit(X_train, Y_train, epochs=1, steps_per_epoch=60000)\n",
    "result = model2.evaluate(X_test, Y_test, steps = 10000)\n",
    "print(\"Loss : \", result[0])\n",
    "print(\"Success Accurcy : \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "60000/60000 [==============================] - 733s 12ms/step - loss: 0.1273 - accuracy: 0.9609\n10000/10000 [==============================] - 27s 3ms/step - loss: 0.0531 - accuracy: 0.9836\nLoss :  0.053102996200323105\nSuccess Accurcy :  0.9836000204086304\n"
    }
   ],
   "source": [
    "# Architecture Three \n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(64, (3, 3), input_shape=(28,28,1)))\n",
    "model3.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model3.add(MaxPooling2D(pool_size=(4,4)))\n",
    "\n",
    "model3.add(Flatten())\n",
    "# Fully connected layer\n",
    "BatchNormalization()\n",
    "model3.add(Dense(512))\n",
    "model3.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model3.add(Dropout(0.2))     #to reduce overfitting\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model3.fit(X_train, Y_train, epochs=1, steps_per_epoch=60000)\n",
    "result = model3.evaluate(X_test, Y_test, steps = 10000)\n",
    "print(\"Loss : \", result[0])\n",
    "print(\"Success Accurcy : \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "60000/60000 [==============================] - 414s 7ms/step - loss: 0.1593 - accuracy: 0.9553\n10000/10000 [==============================] - 19s 2ms/step - loss: 0.0767 - accuracy: 0.9785\nLoss :  0.07665366679430008\nSuccess Accurcy :  0.9785000085830688\n"
    }
   ],
   "source": [
    "# Architecture Four \n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))    #first layer\n",
    "model4.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(4,4)))\n",
    "BatchNormalization(axis=-1)     #normalizes the matrix\n",
    "\n",
    "model4.add(Conv2D(64,(3, 3)))\n",
    "model4.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "\n",
    "model4.add(Conv2D(64, (3, 3)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model4.add(Flatten())\n",
    "# Fully connected layer\n",
    "BatchNormalization()\n",
    "model4.add(Dense(512))\n",
    "model4.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model4.add(Dropout(0.2))     #to reduce overfitting\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model4.fit(X_train, Y_train, epochs=1, steps_per_epoch=60000)\n",
    "result = model4.evaluate(X_test, Y_test, steps = 10000)\n",
    "print(\"Loss : \", result[0])\n",
    "print(\"Success Accurcy : \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}